import os
from openai import OpenAI
import pdfplumber
import json
import pytesseract
from pdf2image import convert_from_path
from PIL import Image
import re

class ResumeParser:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
        
        # Configure Tesseract path (Windows)
        if os.name == 'nt':  # Windows
            pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    
    def extract_text_from_pdf(self, pdf_path):
        """Extract text from PDF using pdfplumber, fallback to OCR"""
        try:
            print(f"   ğŸ“– Trying text extraction with pdfplumber...")
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            
            text = text.strip()
            
            if len(text) > 100:
                print(f"   âœ… Text extraction successful ({len(text)} chars)")
                return text
            else:
                print(f"   âš ï¸  Minimal text found ({len(text)} chars), attempting OCR...")
                return self.extract_text_with_ocr(pdf_path)
                
        except Exception as e:
            print(f"   âŒ Text extraction error: {e}")
            print(f"   ğŸ”„ Falling back to OCR...")
            return self.extract_text_with_ocr(pdf_path)
    
    def extract_text_with_ocr(self, pdf_path):
        """Extract text from PDF using OCR (for scanned documents)"""
        try:
            print(f"   ğŸ” Starting OCR process...")
            images = convert_from_path(pdf_path, dpi=300)
            print(f"   ğŸ“„ Converted to {len(images)} image(s)")
            
            text = ""
            for i, image in enumerate(images):
                print(f"   ğŸ” OCR processing page {i+1}/{len(images)}...")
                page_text = pytesseract.image_to_string(image, lang='eng+ara')
                text += page_text + "\n"
            
            text = text.strip()
            
            if len(text) > 50:
                print(f"   âœ… OCR successful ({len(text)} chars extracted)")
                return text
            else:
                print(f"   âŒ OCR failed - minimal text extracted")
                return None
                
        except Exception as e:
            print(f"   âŒ OCR error: {e}")
            print(f"   ğŸ’¡ Make sure Tesseract is installed and poppler is in PATH")
            return None
    
    def extract_text_from_txt(self, txt_path):
        """Extract text from TXT file"""
        try:
            with open(txt_path, 'r', encoding='utf-8') as file:
                text = file.read()
            return text.strip()
        except Exception as e:
            print(f"Error extracting TXT: {e}")
            return None
    
    def normalize_arabic_text(self, text):
        """
        Normalize Arabic text by removing diacritics and extra whitespace.
        This helps with keyword matching.
        """
        if not text:
            return ""
        
        # Remove Arabic diacritics (tashkeel)
        arabic_diacritics = re.compile(r'[\u064B-\u065F\u0670]')
        text = arabic_diacritics.sub('', text)
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text)
        
        return text
    
    def is_valid_resume(self, resume_text):
        """
        Validate if the extracted text is actually a resume/CV
        Returns: (is_valid: bool, reason: str)
        """
        if not resume_text or len(resume_text.strip()) < 100:
            return False, "Document too short (less than 100 characters)"
        
        text_lower = resume_text.lower()
        
        # Normalize Arabic text for better matching
        normalized_text = self.normalize_arabic_text(resume_text)
        
        # Define CV-related keywords (comprehensive list)
        cv_keywords_english = {
            # Section headers
            'experience', 'education', 'skills', 'work experience', 'employment',
            'qualifications', 'profile', 'summary', 'objective', 'career',
            'professional experience', 'work history', 'academic background',
            'certifications', 'certificates', 'training', 'projects',
            'achievements', 'accomplishments', 'references',
            
            # Contact-related
            'email', 'phone', 'mobile', 'address', 'linkedin', 'portfolio',
            'contact', 'tel', 'website', 'gmail', 'hotmail', 'yahoo',
            
            # Common resume phrases
            'years of experience', 'worked at', 'worked as', 'responsible for',
            'degree in', 'bachelor', 'master', 'diploma', 'graduated',
            'university', 'college', 'institute', 'resume', 'curriculum vitae',
            'cv', 'personal information', 'developer', 'engineer', 'manager',
            'analyst', 'designer', 'specialist', 'coordinator'
        }
        
        # Arabic keywords (normalized - without diacritics and flexible spacing)
        cv_keywords_arabic = [
            # Core sections (most common variations)
            'Ø®Ø¨Ø±Ø©', 'Ø®Ø¨Ø±Ø§Øª', 'Ø§Ù„Ø®Ø¨Ø±Ø©', 'Ø§Ù„Ø®Ø¨Ø±Ø§Øª',
            'ØªØ¹Ù„ÙŠÙ…', 'Ø§Ù„ØªØ¹Ù„ÙŠÙ…', 'Ù…Ø¤Ù‡Ù„', 'Ù…Ø¤Ù‡Ù„Ø§Øª', 'Ø§Ù„Ù…Ø¤Ù‡Ù„', 'Ø§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª',
            'Ù…Ù‡Ø§Ø±Ø©', 'Ù…Ù‡Ø§Ø±Ø§Øª', 'Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª', 'Ø§Ù„Ù…Ù‡Ø§Ø±Ø©',
            'Ø´Ù‡Ø§Ø¯Ø©', 'Ø´Ù‡Ø§Ø¯Ø§Øª', 'Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª',
            'Ø¯ÙˆØ±Ø©', 'Ø¯ÙˆØ±Ø§Øª', 'Ø§Ù„Ø¯ÙˆØ±Ø§Øª',
            'Ù…Ø´Ø±ÙˆØ¹', 'Ù…Ø´Ø§Ø±ÙŠØ¹', 'Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹',
            'Ø§Ù†Ø¬Ø§Ø²', 'Ø§Ù†Ø¬Ø§Ø²Ø§Øª', 'Ø§Ù„Ø§Ù†Ø¬Ø§Ø²Ø§Øª',
            
            # Education terms
            'Ø¨ÙƒØ§Ù„ÙˆØ±ÙŠÙˆØ³', 'Ù…Ø§Ø¬Ø³ØªÙŠØ±', 'Ø¯Ø¨Ù„ÙˆÙ…', 'Ø¯ÙƒØªÙˆØ±Ø§Ù‡',
            'Ø¬Ø§Ù…Ø¹Ø©', 'Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©', 'ÙƒÙ„ÙŠØ©', 'Ø§Ù„ÙƒÙ„ÙŠØ©', 'Ù…Ø¹Ù‡Ø¯', 'Ø§Ù„Ù…Ø¹Ù‡Ø¯',
            'ØªØ®Ø±Ø¬', 'Ø§Ù„ØªØ®Ø±Ø¬',
            
            # Experience terms
            'Ø¹Ù…Ù„', 'Ø§Ù„Ø¹Ù…Ù„', 'ÙˆØ¸ÙŠÙØ©', 'Ø§Ù„ÙˆØ¸ÙŠÙØ©',
            'Ø´Ø±ÙƒØ©', 'Ø§Ù„Ø´Ø±ÙƒØ©', 'Ù…Ø¤Ø³Ø³Ø©', 'Ø§Ù„Ù…Ø¤Ø³Ø³Ø©',
            'Ù…Ø·ÙˆØ±', 'Ù…Ù‡Ù†Ø¯Ø³', 'Ù…Ø­Ù„Ù„', 'Ù…ØµÙ…Ù…', 'Ù…Ø¯ÙŠØ±',
            'Ù…Ø·ÙˆØ±Ø©', 'Ù…Ù‡Ù†Ø¯Ø³Ø©', 'Ù…Ø­Ù„Ù„Ø©', 'Ù…ØµÙ…Ù…Ø©', 'Ù…Ø¯ÙŠØ±Ø©',
            
            # Contact/Personal
            'Ø§Ø³Ù…', 'Ø§Ù„Ø§Ø³Ù…', 'Ù‡Ø§ØªÙ', 'Ø§Ù„Ù‡Ø§ØªÙ', 'Ø¬ÙˆØ§Ù„', 'Ø§Ù„Ø¬ÙˆØ§Ù„',
            'Ø¨Ø±ÙŠØ¯', 'Ø§Ù„Ø¨Ø±ÙŠØ¯', 'Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'Ù…ÙˆÙ‚Ø¹', 'Ø§Ù„Ù…ÙˆÙ‚Ø¹',
            'Ø¹Ù†ÙˆØ§Ù†', 'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†', 'Ø¬Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¬Ù†Ø³ÙŠØ©',
            
            # Other common CV terms
            'Ø³ÙŠØ±Ø©', 'Ø§Ù„Ø³ÙŠØ±Ø©', 'Ø°Ø§ØªÙŠØ©', 'Ø§Ù„Ø°Ø§ØªÙŠØ©',
            'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'Ø´Ø®ØµÙŠØ©', 'Ù…Ù„Ø®Øµ', 'Ø§Ù„Ù…Ù„Ø®Øµ',
            'Ù…Ù‡Ù†ÙŠ', 'Ø§Ù„Ù…Ù‡Ù†ÙŠ', 'ØªÙ‚Ù†ÙŠ', 'Ø§Ù„ØªÙ‚Ù†ÙŠ',
            'Ù„ØºØ§Øª', 'Ø§Ù„Ù„ØºØ§Øª', 'Ù„ØºØ©'
        ]
        
        # Count English keywords (case-insensitive)
        english_count = sum(1 for keyword in cv_keywords_english if keyword in text_lower)
        
        # Count Arabic keywords with normalization
        arabic_count = 0
        matched_arabic = []
        for keyword in cv_keywords_arabic:
            normalized_keyword = self.normalize_arabic_text(keyword)
            if normalized_keyword in normalized_text:
                arabic_count += 1
                matched_arabic.append(keyword)
        
        total_keywords = english_count + arabic_count
        
        # Debug: Show which Arabic keywords were found
        if arabic_count > 0:
            print(f"   ğŸ” Arabic keywords found: {', '.join(matched_arabic[:5])}{'...' if len(matched_arabic) > 5 else ''}")
        
        print(f"   ğŸ” CV validation: Found {english_count} English + {arabic_count} Arabic = {total_keywords} total CV keywords")
        
        # Check for Arabic content
        has_arabic = bool(re.search(r'[\u0600-\u06FF]', resume_text))
        if has_arabic:
            print(f"   ğŸ“ Document contains Arabic text")
        
        # Threshold: At least 3 CV-related keywords should be present
        if total_keywords >= 3:
            if arabic_count > 0:
                return True, f"Valid Arabic CV detected ({arabic_count} Arabic keywords, {english_count} English keywords)"
            else:
                return True, f"Valid CV detected ({total_keywords} keywords found)"
        else:
            # If document has Arabic but low keyword count, might be formatting issue
            if has_arabic and arabic_count > 0:
                print(f"   âš ï¸  Arabic CV detected but low keyword count - accepting anyway")
                return True, f"Arabic CV detected with {arabic_count} keywords (accepted with warning)"
            
            return False, f"Does not appear to be a CV (only {total_keywords} CV keywords found). Please upload a document with sections like Skills, Experience, Education."
    
    def parse_resume(self, resume_text, output_language='en'):
        """
        Use OpenAI to parse resume with validation and anti-hallucination
        
        Args:
            resume_text (str): The extracted resume text
            output_language (str): 'en' for English output, 'ar' for Arabic output
        """
        
        if not resume_text or len(resume_text.strip()) < 50:
            print("   âŒ Resume text too short or empty")
            return None
        
        # VALIDATE: Check if this is actually a CV/resume
        is_valid, validation_reason = self.is_valid_resume(resume_text)
        
        if not is_valid:
            print(f"   âŒ VALIDATION FAILED: {validation_reason}")
            return {
                'error': 'NOT_A_CV',
                'message': validation_reason,
                'is_valid_cv': False
            }
        
        print(f"   âœ… VALIDATION PASSED: {validation_reason}")
        print(f"   ğŸŒ Output language: {'Arabic' if output_language == 'ar' else 'English'}")
        
        # BILINGUAL PROMPTS
        if output_language == 'ar':
            # ARABIC OUTPUT
            prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ù…Ø¹ Ù‚Ø¯Ø±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª.

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø­Ø§Ø³Ù…Ø© - Ù„ØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬:
- Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø£Ùˆ Ø£ÙŠ Ù„ØºØ© Ø£Ø®Ø±Ù‰
- ÙŠØ¬Ø¨ Ø£Ù† ØªØ¹ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø´Ø­ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù…Ø«Ù„ John Smith)ØŒ Ø§Ø­ØªÙØ¸ Ø¨Ù‡ ÙƒÙ…Ø§ Ù‡Ùˆ
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø´Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù…Ø«Ù„ Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯)ØŒ Ø§Ø­ØªÙØ¸ Ø¨Ù‡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- ØªØ±Ø¬Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©ØŒ Ø§Ù„Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„ÙˆØ¸ÙŠÙÙŠØ©ØŒ ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø­ÙŠØ«Ù…Ø§ Ø£Ù…ÙƒÙ†
- Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„ØªÙŠ Ù„ÙŠØ³ Ù„Ù‡Ø§ ØªØ±Ø¬Ù…Ø© Ø¹Ø±Ø¨ÙŠØ© Ø´Ø§Ø¦Ø¹Ø© (Ù…Ø«Ù„ Flutter, Python) Ø§ØªØ±ÙƒÙ‡Ø§ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©

Ù‚ÙˆØ§Ø¹Ø¯ Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„ØªÙ‡ÙŠØ¤Ø§Øª - Ø­Ø§Ø³Ù…Ø©:
1. Ø§Ø³ØªØ®Ø±Ø¬ ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ØµØ±Ø§Ø­Ø©Ù‹ ÙÙŠ Ù†Øµ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©
2. Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø°ÙƒØ± Ø­Ù‚Ù„ Ù…Ø§ØŒ Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ù…ØµÙÙˆÙØ© ÙØ§Ø±ØºØ© []
3. Ù„Ø§ ØªØ³ØªÙ†ØªØ¬ØŒ Ù„Ø§ ØªÙØªØ±Ø¶ØŒ ÙˆÙ„Ø§ ØªÙˆÙ„Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
4. Ù„Ø§ ØªØ¶Ù Ù…Ù‡Ø§Ø±Ø§Øª Ø¹Ø§Ù…Ø© Ù„Ù… ØªÙØ°ÙƒØ±
5. Ø¥Ø°Ø§ ÙƒÙ†Øª ØºÙŠØ± Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ø­Ù‚Ù„ Ù…Ø§ØŒ Ø£Ø¶Ù Ø¯Ø±Ø¬Ø© Ø«Ù‚Ø© (0-100)

Ø¹Ù…Ù„ÙŠØ© Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©:
Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ù‚Ø±Ø£ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø¹Ù†Ø§ÙŠØ©
Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø­Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ÙˆØ§Ø¶Ø­Ø© (Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ØŒ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§ØªØŒ Ø§Ù„Ø®Ø¨Ø±Ø©ØŒ Ø§Ù„ØªØ¹Ù„ÙŠÙ…)
Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ø³ØªØ®Ø±Ø¬ ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ØµØ±Ø§Ø­Ø©Ù‹
Ø§Ù„Ø®Ø·ÙˆØ© 4: ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙƒÙ…Ø§ Ù‡ÙŠ)
Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„ Ø­Ù‚Ù„ Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ¯Ø±
Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø£Ø¶Ù Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø«Ù‚Ø©

Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¹Ø¯Ù‡Ø§ Ø¨ØµÙŠØºØ© JSON:

{{
    "Ø§Ù„Ø§Ø³Ù…": "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø±Ø´Ø­ - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø°ÙƒÙˆØ±Ø§Ù‹ Ø¨ÙˆØ¶ÙˆØ­",
    "Ø§Ù„Ø¨Ø±ÙŠØ¯_Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹",
    "Ø§Ù„Ù‡Ø§ØªÙ": "Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ - ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹",
    "Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª": ["Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø´Ø®ØµÙŠØ© - ÙÙ‚Ø· Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ØµØ±Ø§Ø­Ø©Ù‹"],
    "Ø§Ù„Ø®Ø¨Ø±Ø©": "Ù…Ù„Ø®Øµ Ø§Ù„Ø®Ø¨Ø±Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - ÙÙ‚Ø· Ø¥Ø°Ø§ Ø°ÙÙƒØ±Øª",
    "Ø§Ù„ØªØ¹Ù„ÙŠÙ…": "Ø§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - ÙÙ‚Ø· Ø¥Ø°Ø§ Ø°ÙÙƒØ±Øª",
    "Ø§Ù„Ù…Ù„Ø®Øµ": "Ù…Ù„Ø®Øµ Ù…Ù‡Ù†ÙŠ Ù…Ø®ØªØµØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (2-3 Ø¬Ù…Ù„) - Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ",
    "Ø§Ù„Ø«Ù‚Ø©": {{
        "Ø§Ù„Ø§Ø³Ù…": <0-100>,
        "Ø§Ù„Ø¨Ø±ÙŠØ¯_Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": <0-100>,
        "Ø§Ù„Ù‡Ø§ØªÙ": <0-100>,
        "Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª": <0-100>,
        "Ø§Ù„Ø®Ø¨Ø±Ø©": <0-100>,
        "Ø§Ù„ØªØ¹Ù„ÙŠÙ…": <0-100>
    }}
}}

ØªÙ‚ÙŠÙŠÙ… Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©:
- 100: Ø§Ù„Ø­Ù‚Ù„ Ù…Ø°ÙƒÙˆØ± Ø¨ÙˆØ¶ÙˆØ­ ÙˆØµØ±Ø§Ø­Ø©
- 80-99: Ø§Ù„Ø­Ù‚Ù„ Ù…ÙˆØ¬ÙˆØ¯ ÙˆÙ„ÙƒÙ† Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙØ³ÙŠØ± Ø¨Ø³ÙŠØ·
- 60-79: Ø§Ù„Ø­Ù‚Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¬Ø²Ø¦ÙŠØ§Ù‹ Ø£Ùˆ ÙŠØªØ·Ù„Ø¨ ØªØ±Ø¬Ù…Ø©
- 40-59: Ø§Ù„Ø­Ù‚Ù„ Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ (Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø­Ø°Ø±)
- 0-39: Ø§Ù„Ø­Ù‚Ù„ ØºÙŠØ± Ù…Ø¤ÙƒØ¯ Ø£Ùˆ Ù…ÙÙ‚ÙˆØ¯ (Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹)

Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ø¬Ù…Ø©:
- "Software Engineer" â†’ "Ù…Ù‡Ù†Ø¯Ø³ Ø¨Ø±Ù…Ø¬ÙŠØ§Øª"
- "Python" â†’ "Python" (Ø§ØªØ±Ùƒ ÙƒÙ…Ø§ Ù‡ÙŠ)
- "University of Jordan" â†’ "Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©"
- "Mobile App Developer" â†’ "Ù…Ø·ÙˆØ± ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…ÙˆØ¨Ø§ÙŠÙ„"

Ø­Ø§Ø³Ù…: Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Øµ Ù…Ù† OCR ÙˆÙ‚Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø®Ø·Ø§Ø¡. ÙƒÙ† Ù…Ø±Ù†Ø§Ù‹ ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªØªØ®ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.
Ø¥Ø°Ø§ Ù„Ù… ØªØªÙ…ÙƒÙ† Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯ Ø­Ù‚Ù„ Ø¨Ø«Ù‚Ø© > 60ØŒ Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹.

Ù†Øµ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©:
{resume_text}

Ø£Ø¹Ø¯ ÙÙ‚Ø· JSON ØµØ­ÙŠØ­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ø£Ùˆ ØªÙ†Ø³ÙŠÙ‚ markdown.
"""
            system_content = "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø³ÙŠØ± Ø°Ø§ØªÙŠØ© Ù…Ø­ØªØ±Ù Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª. Ù„Ø§ ØªØªØ®ÙŠÙ„ Ø£Ùˆ ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¨Ø¯Ø§Ù‹. ÙŠÙ…ÙƒÙ†Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø¨Ø£ÙŠ Ù„ØºØ© ÙˆÙ„ÙƒÙ† Ø£Ø¹Ø¯ Ø¯Ø§Ø¦Ù…Ø§Ù‹ JSON ØµØ­ÙŠØ­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·. ØªØ±Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©. Ù„Ø§ ØªØ¶Ù…Ù† ÙƒØªÙ„ Ø£ÙƒÙˆØ§Ø¯ markdown Ø£Ùˆ Ø£ÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø¢Ø®Ø±. ÙƒÙ† Ù…ØªØ³Ø§Ù…Ø­Ø§Ù‹ Ù…Ø¹ Ø£Ø®Ø·Ø§Ø¡ OCR ÙˆÙ„ÙƒÙ† Ø§Ø³ØªØ®Ø±Ø¬ ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ¯Ø±. Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† ØºÙŠØ± Ù…ØªØ£ÙƒØ¯ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ø±Ø¬Ø§Øª Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©."
        
        else:
            # ENGLISH OUTPUT (Original)
            prompt = f"""
You are an expert resume parser with multilingual capabilities.

CRITICAL INSTRUCTION - OUTPUT LANGUAGE:
- The resume may be in English, Arabic, or any other language
- You MUST return ALL extracted information in ENGLISH
- If the candidate's name is in Arabic (e.g., Ø£Ø­Ù…Ø¯ Ù…Ø­Ù…Ø¯), transliterate it to English (e.g., Ahmed Mohammed)
- Translate all skills, job titles, companies, and education to English
- Preserve the original meaning while converting to English

ANTI-HALLUCINATION RULES - CRITICAL:
1. ONLY extract information that is EXPLICITLY stated in the resume text
2. If a field is not mentioned, leave it empty or use empty array []
3. DO NOT infer, assume, or generate information not present
4. DO NOT add generic skills that aren't mentioned
5. If uncertain about a field, include a confidence score (0-100)

STEP-BY-STEP PROCESS:
Step 1: Read the entire resume carefully
Step 2: Identify clear sections (contact, skills, experience, education)
Step 3: Extract ONLY explicitly mentioned information
Step 4: Translate/transliterate to English
Step 5: Verify each extracted field against source text
Step 6: Assign confidence scores

Extract the following information and return it in JSON format:

{{
    "name": "candidate's full name (in English/transliterated) - ONLY if clearly stated",
    "email": "email address - ONLY if present",
    "phone": "phone number - ONLY if present",
    "skills": ["list of technical and soft skills in English - ONLY skills explicitly mentioned"],
    "experience": "work experience summary in English - ONLY if mentioned",
    "education": "educational qualifications in English - ONLY if mentioned",
    "summary": "brief professional summary in English (2-3 sentences) - based on actual content",
    "confidence": {{
        "name": <0-100>,
        "email": <0-100>,
        "phone": <0-100>,
        "skills": <0-100>,
        "experience": <0-100>,
        "education": <0-100>
    }}
}}

CONFIDENCE SCORING:
- 100: Field is clearly and explicitly stated
- 80-99: Field is present but may need minor interpretation
- 60-79: Field is partially present or requires translation
- 40-59: Field is inferred from context (use cautiously)
- 0-39: Field is uncertain or missing (leave empty)

Examples of translation/transliteration:
- "Ù…Ù‡Ù†Ø¯Ø³ Ø¨Ø±Ù…Ø¬ÙŠØ§Øª" â†’ "Software Engineer"
- "Ø¨Ø§ÙŠØ«ÙˆÙ†" â†’ "Python"
- "Ø§Ù„Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ©" â†’ "University of Jordan"
- "Ù…Ø­Ù…Ø¯ Ø£Ø­Ù…Ø¯" â†’ "Mohammed Ahmed"
- "Ø¢ÙŠØ© Ø®Ø§Ù„Ø¯" â†’ "Aya Khaled"
- "Ù…Ø·ÙˆØ±Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…ÙˆØ¨Ø§ÙŠÙ„" â†’ "Mobile Application Developer"

CRITICAL: The text may come from OCR and might have errors. Be flexible but DO NOT hallucinate.
If you cannot find a field with confidence >60, leave it empty.

Resume text:
{resume_text}

Return ONLY valid JSON in English, no additional text or markdown formatting.
"""
            system_content = "You are a professional multilingual resume parser. You NEVER hallucinate or invent information. You can read resumes in any language but ALWAYS respond with valid JSON in ENGLISH only. Transliterate names and translate all content to English. Do not include markdown code blocks or any other formatting. Be tolerant of OCR errors but ONLY extract information that is actually present in the source text. When uncertain, use low confidence scores."
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": prompt}
                ],
                temperature=0
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # Remove markdown code blocks if present
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
                response_text = response_text.strip()
            
            parsed_data = json.loads(response_text)
            
            # Add validation flag and language
            parsed_data['is_valid_cv'] = True
            parsed_data['output_language'] = output_language
            
            # Quality validation
            confidence_key = 'Ø§Ù„Ø«Ù‚Ø©' if output_language == 'ar' else 'confidence'
            if parsed_data.get(confidence_key):
                avg_confidence = sum(parsed_data[confidence_key].values()) / len(parsed_data[confidence_key])
                print(f"   ğŸ“Š Average confidence: {avg_confidence:.1f}%")
                
                if avg_confidence < 70:
                    print(f"   âš ï¸  Low confidence extraction - resume may be unclear or OCR quality poor")
            
            # Check for Arabic characters in name (for English mode)
            if output_language == 'en' and parsed_data.get('name'):
                if any('\u0600' <= char <= '\u06FF' for char in str(parsed_data.get('name', ''))):
                    print("   âš ï¸  Warning: Name still contains Arabic characters (transliteration incomplete)")
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            print(f"   âŒ JSON parsing error: {e}")
            print(f"   ğŸ“„ Response was: {response_text[:200]}...")
            return None
        except Exception as e:
            print(f"   âŒ Error parsing resume: {e}")
            return None